{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World\n",
    "Basic text Hello World example in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World with a Matrix\n",
    "Hello World with a Matrix from NumPy used to initialize a TensorFlow Variable.\n",
    "Before using the variable, we need to run the initializer operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "y_np = np.array([[1,2,3], [4,5,6]])\n",
    "y_tf = tf.Variable(y_np)\n",
    "# matrix1 = tf.constant([[3., 3.]])  # matrix constant\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "print(sess.run(y_tf))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions Run and Eval\n",
    "* When using \"with\", there is a default session and closing is automatic\n",
    "* eval() uses the default session (which is established inside the \"with\")\n",
    "* A \"sesssion\" parameter must be supplied to eval() when not within a \"with\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42 42 42]\n",
      " [42 42 42]]\n",
      "[[42 42 42]\n",
      " [42 42 42]]\n",
      "[[42 42 42]\n",
      " [42 42 42]]\n"
     ]
    }
   ],
   "source": [
    "const = tf.fill([2, 3], 42, \"test_tensor\")\n",
    "with tf.Session() as sess:\n",
    "    val = sess.run(const)\n",
    "    print(val)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    val2 = const.eval() # uses the default session\n",
    "    print(val2)\n",
    "    \n",
    "sess = tf.Session()\n",
    "val3 = const.eval(session=sess)\n",
    "print(val3)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Variables\n",
    "Shows how to save and restore a counter that increments with each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model_counter_c.ckpt\n",
      "Restored counter= 16.0\n",
      "Saved counter= 17.0\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "path = \"/tmp/model_counter_c.ckpt\"\n",
    "counter = tf.Variable(1.0)\n",
    "increment = tf.assign(counter, counter + 1)\n",
    "saver = tf.train.Saver({\"my_counter\": counter})  # List of parameters to save is optional\n",
    "with tf.Session() as sess:\n",
    "    # Restore previously saved variables\n",
    "    try:\n",
    "        saver.restore(sess, path)\n",
    "        print(\"Restored counter=\", sess.run(counter))\n",
    "    except Exception as e:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"Initialized counter\")\n",
    "    \n",
    "    # Increment the counter\n",
    "    increment.eval()  # This is just alternate syntax for: sess.run(increment)\n",
    "    value = sess.run(counter)\n",
    "    \n",
    "    # Save updated value of the variables\n",
    "    saver.save(sess, path)\n",
    "    print(\"Saved counter=\", value)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy with Logits\n",
    "Given the ideal probability distribution of labels, find the crossentropy from generating y_logits <br/>\n",
    "Note: Logits are in range of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy[0] 1.11 == 1.11\n",
      "Entropy[1] 2.31 == 2.31\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_logits_np = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]) # the estimated values scaled between 0 to 1\n",
    "    y_logits = tf.Variable(y_logits_np, \"y_logits\")\n",
    "    \n",
    "    labels_np = np.array([[.2, .3, .5], [0.9, 0.1, 0.0]])  # the ideal probabilities\n",
    "    labels = tf.Variable(labels_np, \"labels\")\n",
    "    \n",
    "    # Method 1: Using TF built-in function\n",
    "    y_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_logits, labels=labels)\n",
    "    \n",
    "    # Method 2: Showing underlying math\n",
    "    y_softmax = tf.nn.softmax(y_logits) # does not reduce dimensionality\n",
    "    y_entropy2 = -tf.reduce_sum(labels * tf.log(y_softmax), 1) # take the sum of the products along axis=1\n",
    "        \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    y_entropy_val, y_entropy_val2 = sess.run([y_entropy, y_entropy2])\n",
    "\n",
    "    for entropy, entropy2, rowIndex in zip(y_entropy_val, y_entropy_val2, range(y_entropy_val.size)):\n",
    "        print(\"Entropy[%d] %.2f == %.2f\" % (rowIndex, entropy, entropy2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy for sparse distribution\n",
    "When the ideal distribution has a single correct answer, then use sparse function for more efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy[0] 0.41 == 0.41\n",
      "Entropy[1] 1.41 == 1.41\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_logits_np = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]) # the estimated values scaled between 0 to 1\n",
    "    y_logits = tf.Variable(y_logits_np, \"y_logits\")\n",
    "    \n",
    "    label_indexes_np = np.array([2, 1])  # the ideal probability indexes\n",
    "    label_indexes = tf.Variable(label_indexes_np, \"label_indexes\")\n",
    "\n",
    "    # labels_np = np.array([[0.0, 0, 1], [0.0, 1, 0]])  # the ideal probabilities (notice they are one-hot)\n",
    "    labels_np = np.zeros((2, 3))\n",
    "    labels_np[np.arange(2), label_indexes_np] = 1;\n",
    "    labels = tf.Variable(labels_np, \"labels\")\n",
    "\n",
    "\n",
    "    # Method 1: Using TF built-in SPARSE function\n",
    "    y_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_logits, labels=label_indexes)\n",
    "    # Method 2: Using TF built-in non-sparse function (requires labels to be one-hot)\n",
    "    y_entropy2 = tf.nn.softmax_cross_entropy_with_logits(logits=y_logits, labels=labels)\n",
    "        \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    y_entropy_val, y_entropy_val2 = sess.run([y_entropy, y_entropy2])\n",
    "\n",
    "    for entropy, entropy2, rowIndex in zip(y_entropy_val, y_entropy_val2, range(y_entropy_val.size)):\n",
    "        print(\"Entropy[%d] %.2f == %.2f\" % (rowIndex, entropy, entropy2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
