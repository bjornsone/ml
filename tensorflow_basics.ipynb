{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World\n",
    "Basic text Hello World example in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World\n",
    "Hello World with a Matrix from NumPy used to initialize a TensorFlow Variable.\n",
    "Before using the variable, we need to run the initializer operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "y_np = np.array([[1,2,3], [4,5,6]])\n",
    "y_tf = tf.Variable(y_np)\n",
    "# matrix1 = tf.constant([[3., 3.]])  # matrix constant\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "print(sess.run(y_tf))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Variables\n",
    "MUST DEBUG: This is currently not working!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved counter= 2.0\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "path = \"/tmp/model_counter.ckpt\"\n",
    "counter = tf.Variable(1.0)\n",
    "increment = tf.assign(counter, counter + 1)\n",
    "saver = tf.train.Saver({\"my_counter\": counter})  # List of parameters to save is optional\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Restore previously saved variables\n",
    "    if(os.path.exists(path)):\n",
    "        saver.restore(sess, path)\n",
    "        print(\"Restored counter=\", sess.run(counter))\n",
    "    \n",
    "    # Increment the counter\n",
    "    sess.run(increment)\n",
    "    value = sess.run(counter)\n",
    "    \n",
    "    # Save updated value of the variables\n",
    "    saver.save(sess, path)\n",
    "    print(\"Saved counter=\", value)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mnist Data\n",
    "Loads ~55,000 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "x shape =  (100, 784)   y shape =  (100, 10)\n",
      "Total Data Points = 55000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "batch = mnist.train.next_batch(100)\n",
    "x, y = batch[0], batch[1]  # obtain numpy arrays for 100 chars w/ one_hot output\n",
    "print('x shape = ', x.shape, '  y shape = ', y.shape)\n",
    "print('Total Data Points = %d' % mnist.train.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "Includes two layers with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32, name=\"dropout\")  # scalar variable\n",
    "\n",
    "mid_size = 50\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n",
    "\n",
    "weights1 = tf.Variable(tf.random_normal([784, mid_size], stddev=0.35), name=\"weights1\")\n",
    "biases1 = tf.Variable(tf.zeros([mid_size]), name=\"biases1\")\n",
    "\n",
    "weights2 = tf.Variable(tf.random_normal([mid_size, 10], stddev=0.35), name=\"weights2\")\n",
    "biases2 = tf.Variable(tf.zeros([10]), name=\"biases2\")\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    " \n",
    "hidden1 = tf.nn.relu(tf.matmul(x, weights1) + biases1)\n",
    "prediction = tf.nn.softmax(tf.nn.dropout(tf.matmul(hidden1, weights2)+biases2, keep_prob))\n",
    "\n",
    "error = tf.reduce_mean(-tf.reduce_sum(y*tf.log(prediction), reduction_indices=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(.1)  # learning rate\n",
    "train = optimizer.minimize(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "[Good Example Page](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/logistic_regression.py)\n",
    "Testing Markdown:\n",
    "$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0  Error: 0.443\n",
      "Epoch:  10  Error: 0.159\n",
      "Epoch:  20  Error: 0.191\n",
      "Epoch:  30  Error: 0.149\n",
      "Epoch:  40  Error: 0.104\n",
      "Epoch:  50  Error: 0.132\n",
      "Epoch:  60  Error: 0.092\n",
      "Epoch:  70  Error: 0.071\n",
      "Epoch:  80  Error: 0.084\n",
      "Epoch:  90  Error: 0.049\n",
      "Epoch: 100  Error: 0.041\n"
     ]
    }
   ],
   "source": [
    "# tf.argmax(y,1)\n",
    "batch_size = 200\n",
    "mini_batch_count = int(mnist.train.num_examples/batch_size)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for epoch in range(101):\n",
    "        for mini_batch in range(mini_batch_count):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            error_val, _ = sess.run([error, train], feed_dict={x: batch_xs, y: batch_ys, keep_prob: 0.7})\n",
    "        if(epoch % 10 == 0):\n",
    "            error_val = sess.run(error, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})\n",
    "            print(\"Epoch: %3d  Error: %.3f\" % (epoch, error_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
